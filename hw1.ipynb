{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600213180575",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Homework 1 &mdash; KFolds\n",
    "### Connor Hornibrook\n",
    "### Data Mining II &mdash; Dr. Breitzman"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Retrieval and Cleanup\n",
    "\n",
    "For this project, I wanted to do something with the [2016 election data](https://www.kaggle.com/benhamner/2016-us-election) found at Kaggle. I downloaded the available SQLite database which \n",
    "contains three tables:\n",
    "\n",
    "- primary_results &mdash; each candidate's vote share from a given county\n",
    "- county_facts &mdash; table containing demographic and geographic information for counties and states, can be linked to primary_results by joining on their two respective ```FIPS``` columns.\n",
    "- county_facts_dictionary &mdash; a lookup table that provides definitions for the oddly-named columns in county_facts\n",
    "\n",
    "I wanted to make a model to guess who won a given county based on population density, age demographics, and the share of the vote they received.\n",
    "\n",
    "To make things a little simpler as this is just a proof of concept, I decided to limit the range of values to Democratic Party results. I then had to create a view in the database that simply was comprised\n",
    "of only one record per county (the winning candidate numbers), and that cleaned up some of the data. \n",
    "\n",
    "To ensure that this would work with an ```sklearn``` model, I eliminated any county with ```null``` age demographic information, and converted the candidate column to feature numeric ids rather than their actual names. \n",
    "\n",
    "The ```SQL``` for this view can be found below:\n",
    "\n",
    "```sql\n",
    "create view county_winners as\n",
    "select  \n",
    "       case when a.candidate = 'HILLARY CLINTON' then 1\n",
    "            when a.candidate = 'BERNIE SANDERS' then 2\n",
    "            when a.candidate = 'MARTIN O''MALLEY' then 3\n",
    "            else 4 end candidate\n",
    "     , cast(c.fips as integer) state_fips\n",
    "     , cast(a.county_fips as integer) county_fips\n",
    "     , cast(a.fraction_votes as float) vote_pct\n",
    "     , cast(b.age135214 as float) under_5yo_pct\n",
    "     , cast(b.age295214 as float) under_18yo_pct\n",
    "     , cast(b.age775214 as float) over_65yo_pct\n",
    "     , cast(b.pop060210 as float) pop_density\n",
    "from (\n",
    "\tselect\n",
    "\t    fips county_fips\n",
    "\t  , trim(upper(candidate)) candidate\n",
    "\t  , trim(upper(state)) state\n",
    "\t  , fraction_votes\n",
    "\t  , dense_rank() over (\n",
    "\t  \t\tpartition by fips, party\n",
    "\t  \t\torder by fraction_votes desc\n",
    "\t  ) county_place\n",
    "\tfrom primary_results \n",
    "\twhere party = 'Democrat'\n",
    "\tand candidate not in (' No Preference', ' Uncommitted') and fips is not null\n",
    ") a \n",
    "left join county_facts b on a.county_fips = b.fips\n",
    "left join county_facts c on a.state = upper(trim(c.area_name))\n",
    "where a.county_place = 1\n",
    "  and b.age135214 is not null\n",
    "  and b.age295214 is not null\n",
    "  and b.age775214 is not null\n",
    "  and b.pop060210 is not null\n",
    "  and a.fraction_votes is not null;\n",
    ";\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Writing the Script\n",
    "\n",
    "Now that I had a simple database view to use (```select * from county_winners```), I could load it up via ```pandas``` and craft the needed ```numpy``` arrays for my independent and dependent variables.\n",
    "\n",
    "The SQLite database that was used for this project is included in this repository as ```database.sqlite```.\n",
    "\n",
    "To run this outside of this jupyter notebook, simply run ```./kfolds.py [-p, --print-scores]``` in the terminal."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# import needed modules\n",
    "import pandas\n",
    "import sqlite3\n",
    "import pathlib\n",
    "import pickle\n",
    "import argparse\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the election sqlite db\n",
    "_db_path = pathlib.Path(\".\", \"database.sqlite\")\n",
    "\n",
    "# path to serialized model (if it exists)\n",
    "_model_path = pathlib.Path(\".\", \"model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns a Naive Bayes model, will pickle and save locally\n",
    "def get_model():\n",
    "    if _model_path.exists():\n",
    "        with open(str(_model_path), \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "    else:\n",
    "        model = MultinomialNB()\n",
    "        with open(str(_model_path), \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that reads the election data from sqllite, determines the dependent\n",
    "# and independent variables, and scales the actual values\n",
    "def get_data():\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    with sqlite3.connect(_db_path) as conn:\n",
    "        raw = pandas.read_sql_query(\n",
    "            \"select * from county_winners\",\n",
    "            conn\n",
    "        )\n",
    "        y = raw.candidate.to_numpy()\n",
    "        x = raw.drop(columns=\"candidate\").to_numpy()\n",
    "        x = scaler.fit_transform(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulated logic for using KFolds cross validation on\n",
    "# a model, using the input independent/dependent variables.\n",
    "# returns the accuracy scores, and optionally prints them\n",
    "def get_accuracy_scores(x, y, model, print_scores=False):\n",
    "    kf = KFold(n_splits=10)\n",
    "    accuracy_scores = []\n",
    "    for train_i, test_i in kf.split(x):\n",
    "        x_train, x_test, y_train, y_test = x[train_i], x[test_i], y[train_i], y[test_i]\n",
    "        model.fit(x_train, y_train)\n",
    "        score = model.score(x_test, y_test)\n",
    "        accuracy_scores.append(score)\n",
    "        if print_scores:\n",
    "            print(score)\n",
    "    return accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# put it all together\n",
    "def main():\n",
    "    x, y = get_data()\n",
    "    get_accuracy_scores(\n",
    "        x, y, get_model(), print_scores=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7385159010600707\n0.7773851590106007\n0.35335689045936397\n0.45936395759717313\n0.5547703180212014\n0.5441696113074205\n0.4664310954063604\n0.8546099290780141\n0.8439716312056738\n0.3120567375886525\n"
    }
   ],
   "source": [
    "# run it\n",
    "main()"
   ]
  }
 ]
}